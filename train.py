# train.py - è¨“ç·´CNNæ¨¡å‹

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import os

print("=" * 70)
print("é£Ÿå“å“è³ªæª¢æ¸¬AIè¨“ç·´ç³»çµ±")
print("=" * 70)

# 1. è¨­ç½®åƒæ•¸
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 10  # å…ˆè¨“ç·´10è¼ªï¼Œå¯ä»¥æ”¹æˆ20

print(f"\nè¨“ç·´åƒæ•¸:")
print(f"  åœ–ç‰‡å¤§å°: {IMG_SIZE}x{IMG_SIZE}")
print(f"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"  è¨“ç·´è¼ªæ•¸: {EPOCHS}")

# 2. æª¢æŸ¥æ•¸æ“š
print("\næª¢æŸ¥æ•¸æ“šé›†...")
train_fresh = len(os.listdir('data/train/fresh'))
train_stale = len(os.listdir('data/train/stale'))
test_fresh = len(os.listdir('data/test/fresh'))
test_stale = len(os.listdir('data/test/stale'))

print(f"âœ“ è¨“ç·´é›† - æ–°é®®: {train_fresh}, è…çˆ›: {train_stale}")
print(f"âœ“ æ¸¬è©¦é›† - æ–°é®®: {test_fresh}, è…çˆ›: {test_stale}")

# 3. æ•¸æ“šå¢å¼·å’ŒåŠ è¼‰
print("\næ­£åœ¨æº–å‚™æ•¸æ“š...")

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'data/train',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=True
)

test_generator = test_datagen.flow_from_directory(
    'data/test',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False
)

print(f"âœ“ è¨“ç·´æ¨£æœ¬æ•¸: {train_generator.samples}")
print(f"âœ“ æ¸¬è©¦æ¨£æœ¬æ•¸: {test_generator.samples}")
print(f"âœ“ é¡åˆ¥å°æ‡‰: {train_generator.class_indices}")

# 4. å»ºç«‹æ¨¡å‹
print("\næ­£åœ¨å»ºç«‹AIæ¨¡å‹...")

base_model = keras.applications.MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)

base_model.trainable = False

model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

print("âœ“ æ¨¡å‹å»ºç«‹å®Œæˆ")

# 5. è¨“ç·´æ¨¡å‹
print("\n" + "=" * 70)
print(f"é–‹å§‹è¨“ç·´ï¼ˆå…±{EPOCHS}è¼ªï¼‰")
print("=" * 70 + "\n")

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=test_generator,
    verbose=1
)

# 6. è©•ä¼°æ¨¡å‹
print("\n" + "=" * 70)
print("è¨“ç·´å®Œæˆï¼æ­£åœ¨è©•ä¼°...")
print("=" * 70)

test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)

print(f"\nğŸ“Š æ¸¬è©¦é›†çµæœ:")
print(f"  æº–ç¢ºç‡: {test_accuracy*100:.2f}%")
print(f"  æå¤±: {test_loss:.4f}")

# 7. ä¿å­˜æ¨¡å‹
os.makedirs('models', exist_ok=True)
model.save('models/food_quality_detector.h5')
print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜: models/food_quality_detector.h5")

# 8. ç¹ªè£½è¨“ç·´æ›²ç·š
print("\næ­£åœ¨ç”Ÿæˆè¨“ç·´æ›²ç·šåœ–...")

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='è¨“ç·´æº–ç¢ºç‡', linewidth=2)
plt.plot(history.history['val_accuracy'], label='é©—è­‰æº–ç¢ºç‡', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('æº–ç¢ºç‡')
plt.title('æ¨¡å‹æº–ç¢ºç‡')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='è¨“ç·´æå¤±', linewidth=2)
plt.plot(history.history['val_loss'], label='é©—è­‰æå¤±', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('æå¤±')
plt.title('æ¨¡å‹æå¤±')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('training_history.png', dpi=300)
print("âœ“ è¨“ç·´æ›²ç·šå·²ä¿å­˜: training_history.png")

# 9. æ¸¬è©¦å¹¾å¼µåœ–ç‰‡
print("\n" + "=" * 70)
print("æ¸¬è©¦ç¤ºä¾‹åœ–ç‰‡...")
print("=" * 70)

from tensorflow.keras.preprocessing import image

# æ¸¬è©¦æ–°é®®é£Ÿå“
print("\nã€æ¸¬è©¦æ–°é®®é£Ÿå“ã€‘")
test_fresh_folder = 'data/test/fresh'
fresh_images = [f for f in os.listdir(test_fresh_folder) 
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]

for img_name in fresh_images:
    img_path = os.path.join(test_fresh_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    
    prediction = model.predict(img_array, verbose=0)[0][0]
    result = "ğŸ æ–°é®®" if prediction < 0.5 else "ğŸ¤¢ è…çˆ›"
    confidence = (1 - prediction) if prediction < 0.5 else prediction
    
    print(f"  {img_name[:30]}: {result} (ç½®ä¿¡åº¦: {confidence*100:.1f}%)")

# æ¸¬è©¦è…çˆ›é£Ÿå“
print("\nã€æ¸¬è©¦è…çˆ›é£Ÿå“ã€‘")
test_stale_folder = 'data/test/stale'
stale_images = [f for f in os.listdir(test_stale_folder) 
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]

for img_name in stale_images:
    img_path = os.path.join(test_stale_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    
    prediction = model.predict(img_array, verbose=0)[0][0]
    result = "ğŸ æ–°é®®" if prediction < 0.5 else "ğŸ¤¢ è…çˆ›"
    confidence = (1 - prediction) if prediction < 0.5 else prediction
    
    print(f"  {img_name[:30]}: {result} (ç½®ä¿¡åº¦: {confidence*100:.1f}%)")

print("\n" + "=" * 70)
print("âœ… è¨“ç·´å®Œæˆï¼")
print("=" * 70)
print("\nä¸‹ä¸€æ­¥:")
print("  1. æŸ¥çœ‹è¨“ç·´æ›²ç·š: training_history.png")
print("  2. é‹è¡Œæ¼”ç¤ºç•Œé¢: streamlit run app.py")